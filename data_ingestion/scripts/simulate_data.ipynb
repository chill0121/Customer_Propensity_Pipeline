{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e5582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating customer profiles: 100%|██████████| 1000/1000 [00:00<00:00, 18298.64it/s]\n",
      "Generating transactions: 100%|██████████| 1000/1000 [00:01<00:00, 544.73it/s]\n",
      "Generating interactions: 100%|██████████| 1000/1000 [00:00<00:00, 4272.64it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(11)\n",
    "\n",
    "NUM_CUSTOMERS = 1000#500_000\n",
    "START_DATE = datetime(2022, 1, 1)\n",
    "END_DATE = datetime(2025, 5, 30)\n",
    "PRODUCTS = ['checking', 'savings', 'credit_card', 'loan', 'debit']\n",
    "\n",
    "def generate_customer_profiles(num_customers):\n",
    "    profiles = []\n",
    "    for _ in tqdm(range(num_customers), desc=\"Generating customer profiles\"):\n",
    "        profile = {\n",
    "            \"customer_id\": str(uuid.uuid4()),\n",
    "            \"age\": np.random.randint(18, 85),\n",
    "            \"state\": fake.state_abbr(),\n",
    "            \"has_credit_card\": np.random.choice([0, 1]),\n",
    "            \"has_loan\": np.random.choice([0, 1]),\n",
    "            \"has_checking\": 1,\n",
    "            \"has_savings\": np.random.choice([0, 1]),\n",
    "            \"join_date\": fake.date_between(start_date='-10y', end_date='-1y'),\n",
    "            \"gender\": np.random.choice(['M', 'F', 'Other']),\n",
    "        }\n",
    "        profiles.append(profile)\n",
    "    return pd.DataFrame(profiles)\n",
    "\n",
    "def generate_transactions(customers, avg_tx_per_customer=100):\n",
    "    txns = []\n",
    "    for idx, row in tqdm(customers.iterrows(), total=len(customers), desc=\"Generating transactions\"):\n",
    "        # Determine which products the customer has\n",
    "        available_products = [\"checking\", \"debit\"]  # always included\n",
    "        if row[\"has_credit_card\"]:\n",
    "            available_products.append(\"credit_card\")\n",
    "        if row[\"has_loan\"]:\n",
    "            available_products.append(\"loan\")\n",
    "        if row[\"has_savings\"]:\n",
    "            available_products.append(\"savings\")\n",
    "\n",
    "        n_tx = int(np.random.poisson(avg_tx_per_customer))\n",
    "        base_date = START_DATE + timedelta(days=np.random.randint(0, 180))\n",
    "        for _ in range(n_tx):\n",
    "            txn_date = base_date + timedelta(days=np.random.randint(0, (END_DATE - START_DATE).days))\n",
    "            product = np.random.choice(available_products)\n",
    "            amount = np.round(np.random.exponential(scale=100), 2)\n",
    "\n",
    "            txns.append({\n",
    "                \"customer_id\": row[\"customer_id\"],\n",
    "                \"product\": product,\n",
    "                \"amount\": -amount if product in [\"debit\", \"checking\", \"credit_card\"] else amount,\n",
    "                \"txn_type\": np.random.choice(['purchase', 'payment', 'deposit', 'withdrawal']),\n",
    "                \"timestamp\": txn_date\n",
    "            })\n",
    "    return pd.DataFrame(txns)\n",
    "\n",
    "def generate_interactions(customers, avg_int_per_customer=20):\n",
    "    interactions = []\n",
    "    for idx, row in tqdm(customers.iterrows(), total=len(customers), desc=\"Generating interactions\"):\n",
    "        n_int = int(np.random.poisson(avg_int_per_customer))\n",
    "        \n",
    "        # Build a weighted interaction profile\n",
    "        weights = {\n",
    "            'login': 1.0,\n",
    "            'support_call': 0.1,\n",
    "            'email_click': 0.2\n",
    "        }\n",
    "\n",
    "        # Adjust weights based on product ownership\n",
    "        if row[\"has_credit_card\"]:\n",
    "            weights['support_call'] += 0.3\n",
    "            weights['email_click'] += 0.2\n",
    "        if row[\"has_loan\"]:\n",
    "            weights['support_call'] += 0.4\n",
    "            weights['email_click'] += 0.1\n",
    "        if row[\"has_savings\"]:\n",
    "            weights['email_click'] += 0.2\n",
    "        if row[\"has_checking\"]:\n",
    "            weights['login'] += 0.5\n",
    "\n",
    "        # Normalize to make it a probability distribution\n",
    "        total_weight = sum(weights.values())\n",
    "        interaction_types = list(weights.keys())\n",
    "        probabilities = [w / total_weight for w in weights.values()]\n",
    "\n",
    "        for _ in range(n_int):\n",
    "            interactions.append({\n",
    "                \"customer_id\": row[\"customer_id\"],\n",
    "                \"interaction_type\": np.random.choice(interaction_types, p=probabilities),\n",
    "                \"timestamp\": START_DATE + timedelta(days=np.random.randint(0, (END_DATE - START_DATE).days))\n",
    "            })\n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "\n",
    "def generate_churn_labels(customers, transactions):\n",
    "    latest_tx = transactions.groupby(\"customer_id\")[\"timestamp\"].max().reset_index()\n",
    "    latest_tx.columns = [\"customer_id\", \"last_tx_date\"]\n",
    "    today = END_DATE\n",
    "    merged = pd.merge(customers, latest_tx, on=\"customer_id\", how=\"left\")\n",
    "    merged[\"days_since_last_tx\"] = (today - merged[\"last_tx_date\"]).dt.days.fillna(9999)\n",
    "    merged[\"churned\"] = merged[\"days_since_last_tx\"].apply(lambda x: 1 if x > 180 else 0)\n",
    "    return merged[[\"customer_id\", \"churned\"]]\n",
    "\n",
    "# Generate datasets\n",
    "customer_df = generate_customer_profiles(NUM_CUSTOMERS)\n",
    "transaction_df = generate_transactions(customer_df, avg_tx_per_customer=100)\n",
    "interaction_df = generate_interactions(customer_df, avg_int_per_customer=20)\n",
    "churn_df = generate_churn_labels(customer_df, transaction_df)\n",
    "\n",
    "# Save as Parquet for PySpark\n",
    "save_dir = Path(\"..\") / \"raw\"\n",
    "save_dir.mkdir(exist_ok=True)  # Creates directory if it doesn't exist\n",
    "\n",
    "customer_df.to_parquet(save_dir / \"customers.parquet\", index=False)\n",
    "transaction_df.to_parquet(save_dir / \"transactions.parquet\", index=False)\n",
    "interaction_df.to_parquet(save_dir / \"interactions.parquet\", index=False)\n",
    "churn_df.to_parquet(save_dir / \"churn_labels.parquet\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
