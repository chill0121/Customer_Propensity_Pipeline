{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e5582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data generation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating customer profiles: 100%|██████████| 10000/10000 [00:00<00:00, 25365.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 customer profiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating transactions: 100%|██████████| 10000/10000 [00:18<00:00, 529.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1007635 transactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating interactions: 100%|██████████| 10000/10000 [00:08<00:00, 1140.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 218381 interactions\n",
      "Generated churn labels - 1795 churned customers out of 10000\n",
      "\n",
      "=== DATA QUALITY CHECKS ===\n",
      "Transaction date range: 2022-01-01 00:00:00 to 2025-05-29 00:00:00\n",
      "Interaction date range: 2022-01-08 00:00:00 to 2025-05-28 00:00:00\n",
      "Transactions after END_DATE: 0\n",
      "Interactions after END_DATE: 0\n",
      "Churn rate: 17.95%\n",
      "\n",
      "Datasets saved to ../raw/\n",
      "Files created:\n",
      "- customers.parquet\n",
      "- transactions.parquet\n",
      "- interactions.parquet\n",
      "- churn_labels.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "fake = Faker()\n",
    "np.random.seed(11)\n",
    "\n",
    "NUM_CUSTOMERS = 10_000#150_000\n",
    "START_DATE = datetime(2022, 1, 1)\n",
    "END_DATE = datetime(2025, 5, 30)\n",
    "PRODUCTS = ['checking', 'savings', 'credit_card', 'loan', 'debit']\n",
    "\n",
    "def generate_customer_profiles(num_customers):\n",
    "    profiles = []\n",
    "    for _ in tqdm(range(num_customers), desc=\"Generating customer profiles\"):\n",
    "        # Ensure join_date is within our simulation window\n",
    "        join_date = fake.date_between(start_date=START_DATE.date(), end_date=(END_DATE - timedelta(days=30)).date())\n",
    "        \n",
    "        profile = {\n",
    "            \"customer_id\": str(uuid.uuid4()),\n",
    "            \"age\": np.random.randint(18, 85),\n",
    "            \"state\": fake.state_abbr(),\n",
    "            \"has_credit_card\": np.random.choice([0, 1]),\n",
    "            \"has_loan\": np.random.choice([0, 1]),\n",
    "            \"has_checking\": 1,\n",
    "            \"has_savings\": np.random.choice([0, 1]),\n",
    "            \"join_date\": join_date,\n",
    "            \"gender\": np.random.choice(['M', 'F', 'Other']),\n",
    "            \"income_bracket\": np.random.choice(['low', 'medium', 'high'], p=[0.3, 0.5, 0.2])\n",
    "        }\n",
    "        profiles.append(profile)\n",
    "    return pd.DataFrame(profiles)\n",
    "\n",
    "def determine_churn_status(customer_row):\n",
    "    \"\"\"Determine if and when a customer churned based on their profile\"\"\"\n",
    "    # Convert join_date to datetime if it's not already\n",
    "    if isinstance(customer_row['join_date'], str):\n",
    "        join_date = datetime.strptime(customer_row['join_date'], '%Y-%m-%d')\n",
    "    else:\n",
    "        join_date = datetime.combine(customer_row['join_date'], datetime.min.time())\n",
    "    \n",
    "    # Base churn probability (20% of customers churn)\n",
    "    base_churn_prob = 0.2\n",
    "    \n",
    "    # Adjust churn probability based on customer characteristics\n",
    "    churn_prob = base_churn_prob\n",
    "    if customer_row['age'] < 25:  # Young customers more likely to churn\n",
    "        churn_prob += 0.1\n",
    "    if customer_row['has_credit_card'] == 0:  # Less engaged customers\n",
    "        churn_prob += 0.05\n",
    "    if customer_row['has_loan'] == 1:  # Loan customers less likely to churn\n",
    "        churn_prob -= 0.1\n",
    "    if customer_row['income_bracket'] == 'low':\n",
    "        churn_prob += 0.05\n",
    "    \n",
    "    churn_prob = max(0.05, min(0.4, churn_prob))  # Keep between 5% and 40%\n",
    "    \n",
    "    will_churn = np.random.random() < churn_prob\n",
    "    \n",
    "    if will_churn:\n",
    "        # Customer churns between 30 days after joining and 90 days before END_DATE\n",
    "        min_churn_date = join_date + timedelta(days=30)\n",
    "        max_churn_date = END_DATE - timedelta(days=90)\n",
    "        \n",
    "        if min_churn_date < max_churn_date:\n",
    "            days_range = (max_churn_date - min_churn_date).days\n",
    "            churn_date = min_churn_date + timedelta(days=np.random.randint(0, days_range))\n",
    "            return True, churn_date\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "def generate_transactions(customers, avg_tx_per_customer=100):\n",
    "    txns = []\n",
    "    \n",
    "    for idx, row in tqdm(customers.iterrows(), total=len(customers), desc=\"Generating transactions\"):\n",
    "        # Determine churn status\n",
    "        will_churn, churn_date = determine_churn_status(row)\n",
    "        \n",
    "        # Set customer's active period\n",
    "        join_date = datetime.combine(row['join_date'], datetime.min.time()) if isinstance(row['join_date'], type(datetime.now().date())) else row['join_date']\n",
    "        end_date = churn_date if will_churn else END_DATE\n",
    "        \n",
    "        # Skip if join date is after end date\n",
    "        if join_date >= end_date:\n",
    "            continue\n",
    "            \n",
    "        # Determine which products the customer has\n",
    "        available_products = [\"checking\", \"debit\"]  # always included\n",
    "        if row[\"has_credit_card\"]:\n",
    "            available_products.append(\"credit_card\")\n",
    "        if row[\"has_loan\"]:\n",
    "            available_products.append(\"loan\")\n",
    "        if row[\"has_savings\"]:\n",
    "            available_products.append(\"savings\")\n",
    "\n",
    "        # Adjust transaction volume based on customer characteristics\n",
    "        tx_multiplier = 1.0\n",
    "        if row['income_bracket'] == 'high':\n",
    "            tx_multiplier = 1.5\n",
    "        elif row['income_bracket'] == 'low':\n",
    "            tx_multiplier = 0.7\n",
    "        \n",
    "        n_tx = int(np.random.poisson(avg_tx_per_customer * tx_multiplier))\n",
    "        \n",
    "        # Generate transactions only within the customer's active period\n",
    "        active_days = (end_date - join_date).days\n",
    "        if active_days <= 0:\n",
    "            continue\n",
    "            \n",
    "        for _ in range(n_tx):\n",
    "            # Generate transaction date within customer's active period\n",
    "            days_offset = np.random.randint(0, active_days)\n",
    "            txn_date = join_date + timedelta(days=days_offset)\n",
    "            \n",
    "            # Skip transactions after churn date\n",
    "            if will_churn and txn_date >= churn_date:\n",
    "                continue\n",
    "                \n",
    "            product = np.random.choice(available_products)\n",
    "            \n",
    "            # Make amount realistic based on product and customer profile\n",
    "            if product == \"loan\":\n",
    "                amount = np.round(np.random.normal(500, 100), 2)  # Loan payments\n",
    "            elif product == \"credit_card\":\n",
    "                amount = -np.round(np.random.exponential(scale=150), 2)  # Credit purchases (negative)\n",
    "            elif product == \"savings\":\n",
    "                amount = np.round(np.random.exponential(scale=200), 2)  # Deposits (positive)\n",
    "            else:  # checking, debit\n",
    "                amount = -np.round(np.random.exponential(scale=75), 2)  # Debits (negative)\n",
    "            \n",
    "            # Adjust amounts based on income bracket\n",
    "            if row['income_bracket'] == 'high':\n",
    "                amount *= 2\n",
    "            elif row['income_bracket'] == 'low':\n",
    "                amount *= 0.6\n",
    "\n",
    "            txns.append({\n",
    "                \"customer_id\": row[\"customer_id\"],\n",
    "                \"product\": product,\n",
    "                \"amount\": amount,\n",
    "                \"txn_type\": np.random.choice(['purchase', 'payment', 'deposit', 'withdrawal']),\n",
    "                \"timestamp\": txn_date,\n",
    "                \"churned_customer\": will_churn\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(txns)\n",
    "\n",
    "def generate_interactions(customers, transactions, avg_int_per_customer=20):\n",
    "    interactions = []\n",
    "    \n",
    "    # Get customer activity periods from transactions\n",
    "    customer_periods = transactions.groupby('customer_id').agg({\n",
    "        'timestamp': ['min', 'max'],\n",
    "        'churned_customer': 'first'\n",
    "    }).reset_index()\n",
    "    customer_periods.columns = ['customer_id', 'first_tx', 'last_tx', 'churned_customer']\n",
    "    \n",
    "    for idx, row in tqdm(customers.iterrows(), total=len(customers), desc=\"Generating interactions\"):\n",
    "        # Get customer's transaction period\n",
    "        customer_period = customer_periods[customer_periods['customer_id'] == row['customer_id']]\n",
    "        \n",
    "        if len(customer_period) == 0:\n",
    "            # Customer has no transactions, use join date to a short period\n",
    "            join_date = datetime.combine(row['join_date'], datetime.min.time()) if isinstance(row['join_date'], type(datetime.now().date())) else row['join_date']\n",
    "            start_date = join_date\n",
    "            end_date = min(join_date + timedelta(days=30), END_DATE)\n",
    "            is_churned = False\n",
    "        else:\n",
    "            start_date = customer_period.iloc[0]['first_tx']\n",
    "            end_date = customer_period.iloc[0]['last_tx']\n",
    "            is_churned = customer_period.iloc[0]['churned_customer']\n",
    "        \n",
    "        # Adjust interaction volume based on customer profile\n",
    "        int_multiplier = 1.0\n",
    "        if row['age'] < 30:  # Younger customers interact more digitally\n",
    "            int_multiplier = 1.3\n",
    "        if row['has_credit_card']:\n",
    "            int_multiplier += 0.2\n",
    "        if is_churned:  # Churned customers had fewer interactions\n",
    "            int_multiplier *= 0.7\n",
    "            \n",
    "        n_int = int(np.random.poisson(avg_int_per_customer * int_multiplier))\n",
    "        \n",
    "        # Build a weighted interaction profile\n",
    "        weights = {\n",
    "            'login': 1.0,\n",
    "            'support_call': 0.1,\n",
    "            'email_click': 0.2\n",
    "        }\n",
    "\n",
    "        # Adjust weights based on product ownership\n",
    "        if row[\"has_credit_card\"]:\n",
    "            weights['support_call'] += 0.3\n",
    "            weights['email_click'] += 0.2\n",
    "        if row[\"has_loan\"]:\n",
    "            weights['support_call'] += 0.4\n",
    "            weights['email_click'] += 0.1\n",
    "        if row[\"has_savings\"]:\n",
    "            weights['email_click'] += 0.2\n",
    "        if row[\"has_checking\"]:\n",
    "            weights['login'] += 0.5\n",
    "\n",
    "        # Normalize to make it a probability distribution\n",
    "        total_weight = sum(weights.values())\n",
    "        interaction_types = list(weights.keys())\n",
    "        probabilities = [w / total_weight for w in weights.values()]\n",
    "\n",
    "        # Generate interactions within the customer's active period\n",
    "        active_days = (end_date - start_date).days\n",
    "        if active_days <= 0:\n",
    "            active_days = 1\n",
    "            \n",
    "        for _ in range(n_int):\n",
    "            interaction_date = start_date + timedelta(days=np.random.randint(0, active_days))\n",
    "            \n",
    "            interactions.append({\n",
    "                \"customer_id\": row[\"customer_id\"],\n",
    "                \"interaction_type\": np.random.choice(interaction_types, p=probabilities),\n",
    "                \"timestamp\": interaction_date\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(interactions)\n",
    "\n",
    "def generate_churn_labels(customers, transactions):\n",
    "    \"\"\"Generate churn labels based on actual transaction patterns\"\"\"\n",
    "    # Get the last transaction date for each customer\n",
    "    latest_tx = transactions.groupby(\"customer_id\").agg({\n",
    "        'timestamp': 'max',\n",
    "        'churned_customer': 'first'\n",
    "    }).reset_index()\n",
    "    latest_tx.columns = [\"customer_id\", \"last_tx_date\", \"churned_customer\"]\n",
    "    \n",
    "    # Merge with customer data\n",
    "    merged = pd.merge(customers, latest_tx, on=\"customer_id\", how=\"left\")\n",
    "    \n",
    "    # Calculate days since last transaction\n",
    "    merged[\"days_since_last_tx\"] = (END_DATE - merged[\"last_tx_date\"]).dt.days.fillna(9999)\n",
    "    \n",
    "    # Define churn: either marked as churned during simulation OR no activity for 90+ days\n",
    "    merged[\"churned\"] = ((merged[\"churned_customer\"] == True) | \n",
    "                        (merged[\"days_since_last_tx\"] > 90)).astype(int)\n",
    "    \n",
    "    return merged[[\"customer_id\", \"churned\", \"last_tx_date\", \"days_since_last_tx\"]]\n",
    "\n",
    "# Generate datasets\n",
    "print(\"Starting data generation...\")\n",
    "customer_df = generate_customer_profiles(NUM_CUSTOMERS)\n",
    "print(f\"Generated {len(customer_df)} customer profiles\")\n",
    "\n",
    "transaction_df = generate_transactions(customer_df, avg_tx_per_customer=100)\n",
    "print(f\"Generated {len(transaction_df)} transactions\")\n",
    "\n",
    "interaction_df = generate_interactions(customer_df, transaction_df, avg_int_per_customer=20)\n",
    "print(f\"Generated {len(interaction_df)} interactions\")\n",
    "\n",
    "churn_df = generate_churn_labels(customer_df, transaction_df)\n",
    "print(f\"Generated churn labels - {churn_df['churned'].sum()} churned customers out of {len(churn_df)}\")\n",
    "\n",
    "# Data quality checks\n",
    "print(\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "print(f\"Transaction date range: {transaction_df['timestamp'].min()} to {transaction_df['timestamp'].max()}\")\n",
    "print(f\"Interaction date range: {interaction_df['timestamp'].min()} to {interaction_df['timestamp'].max()}\")\n",
    "print(f\"Transactions after END_DATE: {(transaction_df['timestamp'] > END_DATE).sum()}\")\n",
    "print(f\"Interactions after END_DATE: {(interaction_df['timestamp'] > END_DATE).sum()}\")\n",
    "print(f\"Churn rate: {churn_df['churned'].mean():.2%}\")\n",
    "\n",
    "# Remove the helper columns from dataframes for more realistic feat. engineering\n",
    "transaction_df = transaction_df.drop('churned_customer', axis=1)\n",
    "customer_df = customer_df.drop('income_bracket', axis=1)\n",
    "churn_df = churn_df.drop(['last_tx_date', 'days_since_last_tx'], axis=1)\n",
    "\n",
    "# Save as Parquet for PySpark\n",
    "save_dir = Path(\"..\") / \"raw\"\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "customer_df.to_parquet(save_dir / \"customers.parquet\", index=False)\n",
    "transaction_df.to_parquet(save_dir / \"transactions.parquet\", index=False)\n",
    "interaction_df.to_parquet(save_dir / \"interactions.parquet\", index=False)\n",
    "churn_df.to_parquet(save_dir / \"churn_labels.parquet\", index=False)\n",
    "\n",
    "print(f\"\\nDatasets saved to {save_dir}/\")\n",
    "print(\"Files created:\")\n",
    "print(\"- customers.parquet\")\n",
    "print(\"- transactions.parquet\") \n",
    "print(\"- interactions.parquet\")\n",
    "print(\"- churn_labels.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
